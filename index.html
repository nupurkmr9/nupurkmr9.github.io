
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
	<meta name=viewport content='width=800'>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
      /* Color scheme stolen from Sergey Karayev */
      a {
      color: #1772d0;
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09228;
      text-decoration:none;
      }
      body,td,th {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 12px
      }
      strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 12px;
      }
      heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22 px;
      }
      papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
      }
      name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
      }
	.fade {
	   transition: opacity .2s ease-in-out;
	   -moz-transition: opacity .2s ease-in-out;
	   -webkit-transition: opacity .2s ease-in-out;
	   }
	  


	img {
	    display: inline;
	    margin: 0 auto;
	    width: 100%;
	}
   .image-cropper {
      width: 250px;
      height: 250px;
      position: relative;
      overflow: hidden;
      border-radius: 50%;
  }
    </style>
    <link rel="icon" type="image" href="img/logo.jpg">
    <title>Nupur Kumari</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
    <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
      <tr>
        <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="67%" valign="middle">
                <p align="center">
                  <name>Nupur Kumari</name>
                  </font>
                <p align>I am a currently working in the Media and Data Science Research team at Adobe Inc., Noida.
                  I am interested in computer vision, model robustness, adversarial learning and self-supervision. I did my undergraduation from <a href="http://iitd.ac.in/">Indian Institute of Tenchnology Delhi</a> with a major in Mathematics and Computing.
                 
                <p align=center>
<a href="mailto:nupurkmr9@gmail.com">Email</a> &nbsp/&nbsp
<a href="https://www.linkedin.com/in/nupur-kumari-582369112/">LinkedIn</a> &nbsp/&nbsp
<a href="files/resume.pdf">Resume</a> &nbsp/&nbsp
<a href="https://scholar.google.com/citations?user=vRWKLJ8AAAAJ&hl=en">Google Scholar</a>

                </p>
              </td>
              <td width="33%"><img class="image-cropper" src="img/photo.jpg"></td>
            </tr>
          </table>
            

           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <heading style="font-size:22px"> Publication</heading>
              </td>
            </tr>

          

              <tr >
              <td width="30%"><img id="img-opt" src="img/cutmix_column.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/2012.04256">
        <papertitle>Data Instance Prior for Transfer Learning in GANs</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Puneet Mangla<sup>&#42;</sup>, Nupur Kumari<sup>&#42;</sup>, <a href="https://msingh27.github.io/">Mayank Singh</a><sup>&#42;</sup>, <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N Balasubramanian</a>, Balaji Krishnamurthy</i><br>
                        
                      <p>We propose a novel transfer learning method for GANs in the limited data domain by leveraging informative data prior derived from self-supervised/supervised pre-trained networks trained on a diverse source domain. We demonstrate that the proposed method effectively transfers knowledge to domains with few target images.  
                      <br><br>
                     
                      </p>
                      <!-- [<a href="https://arxiv.org/abs/2012.04256">Paper</a>] -->

                      </a> </p>
                    </td>
            </tr>  


           




            <tr >
              <td width="30%"><img id="img-opt" src="img/ltgan.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/2010.09893">
        <papertitle>LT-GAN: Self-Supervised GAN with Latent Transformation Detection</papertitle></a>><br>
        <i><span style="font-size: 10pt;">
          Parth Patel<sup>&#42;</sup>, Nupur Kumari<sup>&#42;</sup>, <a href="https://msingh27.github.io/">Mayank Singh</a><sup>&#42;</sup>, Balaji Krishnamurthy,</i><br>
        
                      <p>We propose LT-GAN, a self-supervised approach for GAN training to improve the generation quality and image diversity by estimating GAN-induced transformations (i.e. transformations induced in the generated images by perturbing the latent space of generator).
                      <br><br>
                      Work accepted at WACV, 2021.
                      </p>
                      <!-- [<a href="https://arxiv.org/abs/2010.09893">Paper</a>] -->

                      </a> </p>
                    </td>
            </tr> 




          <tr >
              <td width="30%"><img id="img-opt" src="img/robust_attr.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/1911.13073">
        <papertitle>Attributional Robustness Training using Input-Gradient Spatial Alignment</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Nupur Kumari<sup>&#42;</sup>, <a href="https://msingh27.github.io/">Mayank Singh</a><sup>&#42;</sup>, Puneet Mangla, <a href="https://a7b23.github.io/">Abhishek Sinha</a>, <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N Balasubramanian</a>, Balaji Krishnamurthy</i><br>
                        
                      <p>We propose a robust attribution training methodology <i>ART</i> that maximizes the alignment between the input and its attribution map. <i>ART</i> achieves state-of-the-art performance in attributional robustness and weakly supervised object localization on CUB dataset.  It also induces immunity to adversarial and common perturbations on standard vision datasets.    
                      <br><br>
                      Work acccepted at ECCV 2020.
                      </p>
                      [<a href="https://arxiv.org/abs/1911.13073">Paper</a>]
                      [<a href="https://nupurkmr9.github.io/Attributional-Robustness/">Webpage</a>]
                      [<a href="https://github.com/nupurkmr9/Attributional-Robustness">Code</a>]

                      </a> </p>
                    </td>
            </tr>  



            <tr >
              <td width="30%"><img id="img-opt" src="img/few_shot.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/pdf/1907.12087.pdf">
        <papertitle>Charting the Right Manifold: Manifold Mixup for Few-shot Learning</papertitle></a><br>
                  <i><span style="font-size: 10pt;">
          Puneet Mangla<sup>&#42;</sup>, Nupur Kumari<sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, <a href="https://msingh27.github.io/">Mayank Singh</a><sup>&#42;</sup>, <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N Balasubramanian</a>, Balaji Krishnamurthy</i><br>                     
                      <p>Used self-supervision techniques - rotation and exemplar, followed by manifold mixup for few-shot classification tasks.
                      <br><br>
                      The proposed approach beats the current state-of-the-art accuracy on mini-ImageNet, CUB and CIFAR-FS datasets by 3-8%.
                      <br><br>
                      Work accepted at WACV, 2020.       
                      </p>
                      [<a href="https://arxiv.org/pdf/1907.12087.pdf">Paper</a>]
                      [<a href="https://github.com/nupurkmr9/S2M2_fewshot">Code</a>]
                      </a> </p>
                    </td>
                  </tr>
            <tr >



         <td width="30%"><img id="img-opt" src="img/iclr_trustworthy.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/2005.01499">
        <papertitle>On the Benefits of Models with Perceptually-Aligned Gradients</papertitle></a><br>
                   <i><span style="font-size: 10pt;">
          Gunjan Aggarwal<sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, Nupur Kumari<sup>&#42;</sup>,  <a href="https://msingh27.github.io/">Mayank Singh</a><sup>&#42;</sup></i><br>
             
                      <p>In this paper, we leverage models with perceptually-aligned gradients and show that adversarial training with low max-perturbation bound can improve the performance of models on zero-shot transfer learning tasks and weakly supervised object localization.
                      <br><br>
                      Work accepted at ICLR workshop Towards Trustworthy ML, 2020.
                      </p>
                       
                      </a> </p>
                    </td>
            </tr>    



        <td width="30%"><img id="img-opt" src="img/ShapeVis.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/2001.05166">
        <papertitle>ShapeVis: High-dimensional Data Visualization at Scale</papertitle></a><br>
              <i><span style="font-size: 10pt;">
            Nupur Kumari<sup>&#42;</sup>,Siddarth Ramesh<sup>&#42;</sup>, Akash Rupela<sup>&#42;</sup>, Piyush Gupta<sup>&#42;</sup>,Balaji Krishnamurthy </i><br>
                       
                      <p>In this paper, we propose ShapeVis, a scalable visualization technique for point cloud data inspired from topological data analysis. Our method captures the underlying geometric and topological structure of the data in a compressed graphical representation.
                      <br><br>
                      Work accepted at WWW, 2020.
                      </p>
                       
                      </a> </p>
                    </td>
            </tr>    




              <td width="30%"><img id="img-opt" src="img/lat.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/pdf/1905.05186.pdf">
        <papertitle>Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models</papertitle></a><br>
          <i><span style="font-size: 10pt;">
            Nupur Kumari<sup>&#42;</sup>, <a href="https://msingh27.github.io/">Mayank Singh</a><sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, Harshitha Machiraju, Balaji Krishnamurthy, <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N Balasubramanian</a></i><br>
                 
                      <p>We analyzed robust models for vulnerability against adversarial perturbations at the latent layers and proposed a finetuning algorithm which adversarailly trains latent layers of network. The algorithm achieved the state-of-the art adversarial accuracy against strong adversarial attacks.      
                      <br><br>
                      Work accepted at IJCAI, 2019.
                      </p>
                       
                      </a> </p>
                    </td>
                  </tr>    




      <td width="30%"><img id="img-opt" src="img/multi_mapper.png" alt="project_img" width="120" height="120" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/1903.02755">
        <papertitle>Multimapper: Data Density Sensitive Topological Visualization</papertitle></a><br>   
                <i><span style="font-size: 10pt;">
            Bishal Deb, Ankita Sarkar, Nupur Kumari, Akash Rupela, Piyush Gupta,Balaji Krishnamurthy </i><br>
                
                      <p>We proposed an improvement over Mapper (a topological data visualization algorithm) that reduces the
obscuration of topological information by facilitating the cover selection in data density sensitive manner. 
                      <br><br>
                      Work accepted at ICDM Workshop 2018.
                      </p>
                       
                      </a> </p>
                    </td>
                  </tr>    

       <td width="30%"><img id="img-opt" src="img/detection.png" alt="project_img" width="120" height="50" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="http://www.research.ibm.com/labs/ireland/nemesis2018/pdf/paper4.pdf">
        <papertitle>Understanding Adversarial Space through the lens of Attribution</papertitle></a><br>   
              <i><span style="font-size: 10pt;">
            Nupur Kumari<sup>&#42;</sup>, <a href="https://msingh27.github.io/">Mayank Singh</a><sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>,  Balaji Krishnamurthy</i><br>
                 
                      <p>We use the attribution map of images to train an auxiliary model for detecting adversarial examples of the original image classification network.
                      <br><br>
                      Work accepted at Nemesis ECML Workshop 2018.
                      </p>
                       
                      </a> </p>
                    </td>
                  </tr>    


            

            <!-- <tr >
        
                <td width="30%"><img id="img-opt" src="img/zsl.png" alt="project_img" width="160" style="border-style: none">
                </td>
    
                  <td valign="top" width="70%">
                    <p><a href="files/cs772.pdf">
      <papertitle>A survey of Zero Shot Learning</papertitle></a><br>
                      <em>Supervisor: <a href="https://www.cse.iitk.ac.in/users/piyush/">Dr. Piyush Rai</a>, Indian Institute of Technology Kanpur</em><br>
                    <p>Studied different methods of performing Zero Shot Learning(ZSL) - prediction of a label that
                      has been not seen during the training procedure. 
                    <br><br>
                    Implemented two contemporary papers from this area which required learning a common semantic
                    space for embedding images and labels, to perform ZSL task. Focused on dictionary learning as a way to resolve the PDS issue and found that CNN based features drastically improve the classification accuracy.          
                    <p></p>
                    <a href="files/cs772.pdf">report</a> | <a href="files/cs772_poster.pdf">poster</a>
                    </a> </p>
                  </td>
                </tr>

                <tr >
                    <td width="30%"><img id="img-opt" src="img/isomap.png" alt="project_img" width="160" style="border-style: none">
                        </td>
                          <td valign="top" width="70%">
                            <p><a href="files/ee609.pdf">
              <papertitle>Visualization of high dimensional data </papertitle></a><br>
                              <em>Supervisor: <a href = "http://home.iitk.ac.in/~ketan/">Dr. Ketan Rajawat</a>, Indian Institute of Technology Kanpur</em><br>
                            <p>Explored applications of convex optimization for dimensionality reduction, especially
                              over non linear manifolds.
                            <br><br>
                            Compared performance based on visualizations, computational complexities, and error rates
                            obtained in classification tasks. Selected as the <b>best project</b> in the course comprising of over 80 students.
                            <p></p>
                            <a href="files/ee609.pdf">report</a>
                            </a> </p>
                          </td>
                        </tr>
                        <tr >

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td>
                  <heading style="font-size:22px">Internships</heading>
                </td>
              </tr>
              <tr >
                <td width="30%"><img id="img-pgp" src="img/samsung.jpeg" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><a href="http://www.samsung.com/in/aboutsamsung/samsungelectronics/india/rnd/">
          <papertitle>Samsung Research and Development Institute, Bengaluru (SRIB)</papertitle></a><br>
                          <em>Supervisor: Vishwanath Gopalakrishnan, Principal Engineer, SRIB</em> <br>

                        <p>Developed a photo search mobile application based on image classification by using memory efficient CNN architectures.
                        <br><br>
                        Implemented a depth prediction module for 2D images by formulating it as a dense-label regression problem.
                       <p></p>
                        <a href="files/report_pgp.pdf">report</a> | <a href="files/slides_pgp.pdf">slides</a>
                        </a> </p> -->
                      </td>
                    </tr>

                    


            <tr> 
          <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
                <p align="left"><font size="2">
                  <sup>&#42;</sup> denotes equal contribution
                  </font>
          
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right"><font size="2">
                  <a href="http://www.cs.berkeley.edu/~barron/">inspired from this website</a>
                  </font>
                </p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
    </table>

<script type="text/javascript">
var sc_project=11673319; 
var sc_invisible=1; 
var sc_security="327094c7"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - StatCounter" href="http://statcounter.com/"
target="_blank"><img class="statcounter"
src="//c.statcounter.com/11673319/0/327094c7/1/" alt="Web
Analytics Made Easy - StatCounter"></a></div></noscript>
<!-- End of Statcounter Code -->
  </body>
</html>